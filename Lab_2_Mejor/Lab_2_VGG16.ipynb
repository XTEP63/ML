{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P02-XqhFlGWG"
      },
      "source": [
        "**Lab 2. image Classification & CNNs**\n",
        "Dataset de marcas de coches construido por: Esteban Berumen\n",
        "\n",
        "Este código utiliza la arquitectura de VGG16 para conseguir los mejores resultados posibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-jycvr5ij6v7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-mhMf2BImjzb"
      },
      "outputs": [],
      "source": [
        "# Carga de datos de CSV\n",
        "train_df = pd.read_csv('train_dataset.csv')\n",
        "test_df = pd.read_csv('test_dataset.csv')\n",
        "\n",
        "# Directorios de imágenes\n",
        "base_dir = os.getcwd()\n",
        "folder_Train = os.path.join(base_dir, 'Train')\n",
        "folder_Test = os.path.join(base_dir, 'Test')\n",
        "\n",
        "# Tamaño de las imágenes\n",
        "img_size = (128, 128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-njJoXLFDqJ",
        "outputId": "4fe4f657-b158-455c-f57e-ee50e48fb5eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"unrar\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n",
            "\"unrar\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        }
      ],
      "source": [
        "!unrar x Test.rar\n",
        "!unrar x Train.rar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vjmbwrWnCmA",
        "outputId": "97cb82d3-8fb1-40c5-bb68-1ea9951b6e44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Medidas Datos Train: (600, 128, 128, 3)\n",
            "Medidas Target Train: (600, 10)\n",
            "Medidas Datos Test: (60, 128, 128, 3)\n",
            "Medidas Target Test: (60, 10)\n"
          ]
        }
      ],
      "source": [
        "# Función para cargar las imágenes y etiquetas\n",
        "\n",
        "def load_images_from_df(df, folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for index, row in df.iterrows():\n",
        "        class_name = row['target']\n",
        "        img_path = os.path.join(folder, class_name, row['filename'])\n",
        "        try:\n",
        "            img = load_img(img_path, target_size=img_size)\n",
        "            img_array = img_to_array(img)\n",
        "            images.append(img_array)\n",
        "            labels.append(class_name)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"El archivo no fue encontrado: {img_path}\")\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Cargar imágenes y etiquetas de entrenamiento y prueba\n",
        "X_train, y_train = load_images_from_df(train_df, folder_Train)\n",
        "X_test, y_test = load_images_from_df(test_df, folder_Test)\n",
        "\n",
        "# Convertir etiquetas a valores numéricos y luego a formato one-hot\n",
        "y_train = pd.Series(y_train)\n",
        "y_test = pd.Series(y_test)\n",
        "y_train, uniques = pd.factorize(y_train)\n",
        "y_test = pd.Categorical(y_test, categories=uniques).codes  # Mismo orden de categorías\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Normalización de los datos de entrada\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Imprimir formas de los datos\n",
        "print(f\"Medidas Datos Train: {X_train.shape}\")\n",
        "print(f\"Medidas Target Train: {y_train.shape}\")\n",
        "print(f\"Medidas Datos Test: {X_test.shape}\")\n",
        "print(f\"Medidas Target Test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVeNjy6tGMzz",
        "outputId": "2d7d04b6-cf86-45ba-ba95-10e6c0bbd47c"
      },
      "outputs": [],
      "source": [
        "# Definir el modelo VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Congelar las capas del modelo base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model.layers[-8:]:  # Descongela las últimas 8 capas\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4zoGBF1LKAIA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "output = Dense(10, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gFiO11pDKIOQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Desactiva el 50% de las neuronas de esta capa\n",
        "output = Dense(10, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tXRU-FnRKMvm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w7YpSJeTGWg2"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)  \n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp7FVPtnGdCO",
        "outputId": "aa4eaaae-e508-4e56-bf13-392b145ea3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "19/19 [==============================] - 41s 2s/step - loss: 2.2417 - accuracy: 0.1917 - val_loss: 1.7912 - val_accuracy: 0.3500\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 47s 3s/step - loss: 1.3293 - accuracy: 0.5617 - val_loss: 0.9807 - val_accuracy: 0.6333\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 58s 3s/step - loss: 0.5585 - accuracy: 0.8133 - val_loss: 1.1576 - val_accuracy: 0.5667\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 50s 3s/step - loss: 0.3015 - accuracy: 0.9083 - val_loss: 1.1012 - val_accuracy: 0.6167\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 64s 3s/step - loss: 0.1708 - accuracy: 0.9517 - val_loss: 0.9950 - val_accuracy: 0.6833\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 51s 3s/step - loss: 0.0349 - accuracy: 0.9917 - val_loss: 0.7830 - val_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 63s 3s/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 1.0494 - val_accuracy: 0.7667\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 61s 3s/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.6667\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 59s 3s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 62s 3s/step - loss: 9.8740e-04 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.8000\n"
          ]
        }
      ],
      "source": [
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlWOlulgGjih",
        "outputId": "9f097080-ccab-441f-9941-f713ddc19ee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 3s 1s/step - loss: 0.7906 - accuracy: 0.8000\n",
            "Precisión en el conjunto de prueba: 80.00%\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo en el conjunto de prueba\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Precisión en el conjunto de prueba: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 559ms/step\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
            "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
            "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
            "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def visualize_activations_from_test_set(model, X_test, layer_indices, num_images=5):\n",
        "    layer_outputs = [model.layers[i].output for i in layer_indices]\n",
        "    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "    activations = activation_model.predict(X_test[:num_images])  \n",
        "\n",
        "    for layer_index, activation in zip(layer_indices, activations):\n",
        "        num_filters = activation.shape[-1]\n",
        "        cols = 8  \n",
        "        rows = (num_filters + cols - 1) // cols  \n",
        "\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(20, 2 * rows))\n",
        "        fig.suptitle(f'Activations of Layer {model.layers[layer_index].name}', fontsize=16)\n",
        "\n",
        "        for filter_index in range(num_filters):\n",
        "            for img_index in range(num_images):\n",
        "                ax_index = img_index * num_filters + filter_index\n",
        "                if ax_index < rows * cols:  \n",
        "                    ax = axes.flatten()[ax_index]\n",
        "                    ax.imshow(activation[img_index, :, :, filter_index], cmap='viridis')\n",
        "                    ax.axis('off')\n",
        "                else:\n",
        "                    break  \n",
        "        plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "        plt.show()\n",
        "\n",
        "layer_indices = [4, 9, 13, 19]  \n",
        "num_images_to_visualize = 3  \n",
        "visualize_activations_from_test_set(model, X_test, layer_indices, num_images=num_images_to_visualize)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
