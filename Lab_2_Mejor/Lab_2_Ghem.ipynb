{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_2480\\2198283948.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "base_dir = os.getcwd() \n",
    "folder_Train = os.path.join(base_dir, 'Train')\n",
    "folder_Test = os.path.join(base_dir, 'Test')\n",
    "\n",
    "img_size = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_df(df, folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        class_name = row['target']  \n",
    "        img_path = os.path.join(folder, class_name, row['filename'])  \n",
    "        try:\n",
    "            img = load_img(img_path, target_size=img_size)\n",
    "            img_array = img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(class_name)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"El archivo no fue encontrado: {img_path}\")\n",
    "    return np.array(images), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_images_from_df(train_df, folder_Train)\n",
    "X_test, y_test = load_images_from_df(test_df, folder_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.Series(y_train)\n",
    "y_test = pd.Series(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train= label_encoder.fit_transform(y_train)\n",
    "y_test= label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10) \n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas Datos Train: (600, 128, 128, 3)\n",
      "Medidas Target Train: (600, 10)\n",
      "Medidas Datos Test: (60, 128, 128, 3)\n",
      "Medidas Target Test: (60, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Medidas Datos Train: {X_train.shape}\")\n",
    "print(f\"Medidas Target Train: {y_train.shape}\")\n",
    "print(f\"Medidas Datos Test: {X_test.shape}\")\n",
    "print(f\"Medidas Target Test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_zoom         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomZoom</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_rotation     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ random_zoom[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomRotation</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_width        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ random_rotation[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomWidth</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_height       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ random_width[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomHeight</span>)      │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_flip         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ random_height[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)        │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │ random_flip[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │ random_flip[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_zoom         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mRandomZoom\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_rotation     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ random_zoom[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mRandomRotation\u001b[0m)    │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_width        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;45mNone\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ random_rotation[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomWidth\u001b[0m)       │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_height       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ random_width[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomHeight\u001b[0m)      │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_flip         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ random_height[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mRandomFlip\u001b[0m)        │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m14,714,688\u001b[0m │ random_flip[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m20,024,384\u001b[0m │ random_flip[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ functional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │            │ functional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m262,400\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m2,570\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,005,066</span> (133.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,005,066\u001b[0m (133.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">265,482</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m265,482\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,739,584</span> (132.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,739,584\u001b[0m (132.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import RandomZoom, RandomRotation, RandomWidth, RandomHeight, RandomFlip\n",
    "\n",
    "# Definir la arquitectura completa de VGG16\n",
    "def build_vgg16():\n",
    "    inputs = keras.Input(shape=(128, 128, 3))\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    return keras.Model(inputs, x)\n",
    "\n",
    "# Definir la arquitectura completa de VGG19\n",
    "def build_vgg19():\n",
    "    inputs = keras.Input(shape=(128, 128, 3))\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    return keras.Model(inputs, x)\n",
    "\n",
    "# Construir los modelos VGG16 y VGG19\n",
    "vgg16_base = build_vgg16()\n",
    "vgg19_base = build_vgg19()\n",
    "\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "\n",
    "# Cargar los pesos preentrenados de Keras automáticamente\n",
    "vgg16_base.set_weights(VGG16(include_top=False, weights='imagenet').get_weights())\n",
    "vgg19_base.set_weights(VGG19(include_top=False, weights='imagenet').get_weights())\n",
    "\n",
    "# Congelar las capas de los modelos base\n",
    "vgg16_base.trainable = False\n",
    "vgg19_base.trainable = False\n",
    "\n",
    "# Crear un nuevo modelo híbrido \n",
    "inputs = keras.Input(shape=(128, 128, 3))\n",
    "\n",
    "x = RandomZoom(0.2)(inputs)  # Zoom in hasta un 20%\n",
    "x = RandomRotation(0.2)(x)\n",
    "x = RandomWidth(0.2)(x)\n",
    "x = RandomHeight(0.2)(x)\n",
    "x = RandomFlip('horizontal')(x)\n",
    "\n",
    "# Pasar las imágenes augmentadas a través de VGG16 y VGG19\n",
    "x_vgg16 = vgg16_base(x)\n",
    "x_vgg19 = vgg19_base(x)\n",
    "\n",
    "# Combinar las salidas de ambos modelos\n",
    "combined = keras.layers.Concatenate()([x_vgg16, x_vgg19])\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D()(combined)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Crear el modelo final\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de EarlyStopping y ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.0939 - loss: 3.5287 - val_accuracy: 0.1667 - val_loss: 5.5966\n",
      "Epoch 2/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.1979 - loss: 2.8682 - val_accuracy: 0.1500 - val_loss: 3.6643\n",
      "Epoch 3/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.2736 - loss: 2.4465 - val_accuracy: 0.2167 - val_loss: 3.1539\n",
      "Epoch 4/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.3220 - loss: 2.2081 - val_accuracy: 0.2167 - val_loss: 3.0093\n",
      "Epoch 5/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.3587 - loss: 2.0378 - val_accuracy: 0.3000 - val_loss: 2.6877\n",
      "Epoch 6/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.3720 - loss: 1.9474 - val_accuracy: 0.3667 - val_loss: 2.4375\n",
      "Epoch 7/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.4129 - loss: 1.8615 - val_accuracy: 0.3500 - val_loss: 2.3495\n",
      "Epoch 8/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.3905 - loss: 1.7991 - val_accuracy: 0.3167 - val_loss: 2.2882\n",
      "Epoch 9/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.4789 - loss: 1.6623 - val_accuracy: 0.3167 - val_loss: 2.1253\n",
      "Epoch 10/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 5s/step - accuracy: 0.4901 - loss: 1.5349 - val_accuracy: 0.3167 - val_loss: 2.0817\n",
      "Epoch 11/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.4322 - loss: 1.6676 - val_accuracy: 0.3167 - val_loss: 2.2635\n",
      "Epoch 12/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 4s/step - accuracy: 0.5307 - loss: 1.3511 - val_accuracy: 0.3167 - val_loss: 2.1732\n",
      "Epoch 13/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.5382 - loss: 1.3933 - val_accuracy: 0.3500 - val_loss: 2.0431\n",
      "Epoch 14/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.5536 - loss: 1.3392 - val_accuracy: 0.3000 - val_loss: 1.9780\n",
      "Epoch 15/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 5s/step - accuracy: 0.5532 - loss: 1.3591 - val_accuracy: 0.3167 - val_loss: 1.9376\n",
      "Epoch 16/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.5616 - loss: 1.3055 - val_accuracy: 0.2833 - val_loss: 1.9330\n",
      "Epoch 17/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.5351 - loss: 1.3037 - val_accuracy: 0.3000 - val_loss: 1.8118\n",
      "Epoch 18/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5s/step - accuracy: 0.6035 - loss: 1.1895 - val_accuracy: 0.3333 - val_loss: 1.8081\n",
      "Epoch 19/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.6172 - loss: 1.0958 - val_accuracy: 0.3500 - val_loss: 1.8500\n",
      "Epoch 20/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.5961 - loss: 1.1839 - val_accuracy: 0.3833 - val_loss: 1.8434\n",
      "Epoch 21/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.5663 - loss: 1.2173 - val_accuracy: 0.3667 - val_loss: 1.9707\n",
      "Epoch 22/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 4s/step - accuracy: 0.6249 - loss: 1.1158 - val_accuracy: 0.3667 - val_loss: 1.9332\n",
      "Epoch 23/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 5s/step - accuracy: 0.6399 - loss: 1.1383 - val_accuracy: 0.4000 - val_loss: 1.9365\n",
      "Epoch 24/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.6074 - loss: 1.1782 - val_accuracy: 0.3833 - val_loss: 1.8721\n",
      "Epoch 25/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.6402 - loss: 1.0225 - val_accuracy: 0.3833 - val_loss: 1.7619\n",
      "Epoch 26/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.6100 - loss: 1.1292 - val_accuracy: 0.3833 - val_loss: 1.7713\n",
      "Epoch 27/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.6693 - loss: 0.9220 - val_accuracy: 0.3667 - val_loss: 1.8946\n",
      "Epoch 28/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.6376 - loss: 0.9451 - val_accuracy: 0.4000 - val_loss: 1.9328\n",
      "Epoch 29/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.6679 - loss: 0.9878 - val_accuracy: 0.4333 - val_loss: 1.7986\n",
      "Epoch 30/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.6648 - loss: 1.0567 - val_accuracy: 0.4333 - val_loss: 1.8049\n",
      "Epoch 31/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.6722 - loss: 0.9507 - val_accuracy: 0.4500 - val_loss: 1.7768\n",
      "Epoch 32/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.6894 - loss: 0.9796 - val_accuracy: 0.4167 - val_loss: 1.8561\n",
      "Epoch 33/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.6766 - loss: 0.8960 - val_accuracy: 0.4500 - val_loss: 1.7319\n",
      "Epoch 34/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.7337 - loss: 0.7784 - val_accuracy: 0.4167 - val_loss: 1.6738\n",
      "Epoch 35/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.7057 - loss: 0.8982 - val_accuracy: 0.4500 - val_loss: 1.6997\n",
      "Epoch 36/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.6945 - loss: 0.8857 - val_accuracy: 0.4833 - val_loss: 1.6838\n",
      "Epoch 37/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.6984 - loss: 0.9224 - val_accuracy: 0.5000 - val_loss: 1.6845\n",
      "Epoch 38/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.7449 - loss: 0.8365 - val_accuracy: 0.5333 - val_loss: 1.7342\n",
      "Epoch 39/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.7544 - loss: 0.7570 - val_accuracy: 0.5167 - val_loss: 1.7194\n",
      "Epoch 40/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.7336 - loss: 0.8013 - val_accuracy: 0.4500 - val_loss: 1.8352\n",
      "Epoch 41/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 5s/step - accuracy: 0.7601 - loss: 0.7325 - val_accuracy: 0.4667 - val_loss: 1.7834\n",
      "Epoch 42/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.7422 - loss: 0.8371 - val_accuracy: 0.4833 - val_loss: 1.7547\n",
      "Epoch 43/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.7749 - loss: 0.6977 - val_accuracy: 0.4500 - val_loss: 1.7651\n",
      "Epoch 44/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.6806 - loss: 0.7665 - val_accuracy: 0.4333 - val_loss: 1.7648\n",
      "Epoch 45/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.7388 - loss: 0.7392 - val_accuracy: 0.4500 - val_loss: 1.6834\n",
      "Epoch 46/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 5s/step - accuracy: 0.7733 - loss: 0.6905 - val_accuracy: 0.4833 - val_loss: 1.6723\n",
      "Epoch 47/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.7316 - loss: 0.7490 - val_accuracy: 0.4333 - val_loss: 1.6640\n",
      "Epoch 48/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 0.7414 - loss: 0.7345 - val_accuracy: 0.4333 - val_loss: 1.6602\n",
      "Epoch 49/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 5s/step - accuracy: 0.7472 - loss: 0.7591 - val_accuracy: 0.5000 - val_loss: 1.6299\n",
      "Epoch 50/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.7393 - loss: 0.7234 - val_accuracy: 0.4500 - val_loss: 1.6994\n",
      "Epoch 51/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - accuracy: 0.7744 - loss: 0.7226 - val_accuracy: 0.3667 - val_loss: 2.3496\n",
      "Epoch 52/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.7559 - loss: 0.6962 - val_accuracy: 0.3333 - val_loss: 2.2116\n",
      "Epoch 53/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 5s/step - accuracy: 0.7393 - loss: 0.7244 - val_accuracy: 0.3833 - val_loss: 1.8964\n",
      "Epoch 54/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.7944 - loss: 0.6371 - val_accuracy: 0.4167 - val_loss: 1.8069\n",
      "Epoch 55/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - accuracy: 0.7487 - loss: 0.6744 - val_accuracy: 0.4167 - val_loss: 1.7124\n",
      "Epoch 56/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.7870 - loss: 0.6281 - val_accuracy: 0.3833 - val_loss: 1.6977\n",
      "Epoch 57/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - accuracy: 0.8007 - loss: 0.5973 - val_accuracy: 0.3833 - val_loss: 1.7392\n",
      "Epoch 58/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 4s/step - accuracy: 0.7655 - loss: 0.6633 - val_accuracy: 0.4167 - val_loss: 1.8529\n",
      "Epoch 59/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.7511 - loss: 0.7315 - val_accuracy: 0.4500 - val_loss: 1.7425\n",
      "Epoch 60/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.7843 - loss: 0.7011 - val_accuracy: 0.4333 - val_loss: 1.7107\n",
      "Epoch 61/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.7889 - loss: 0.6078 - val_accuracy: 0.4500 - val_loss: 1.6970\n",
      "Epoch 62/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.7755 - loss: 0.6458 - val_accuracy: 0.4167 - val_loss: 1.7732\n",
      "Epoch 63/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.8235 - loss: 0.5773 - val_accuracy: 0.4333 - val_loss: 1.7197\n",
      "Epoch 64/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.7780 - loss: 0.6422 - val_accuracy: 0.4667 - val_loss: 1.7484\n",
      "Epoch 65/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.7719 - loss: 0.6387 - val_accuracy: 0.4333 - val_loss: 1.7892\n",
      "Epoch 66/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.7474 - loss: 0.6964 - val_accuracy: 0.4167 - val_loss: 1.7018\n",
      "Epoch 67/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.7729 - loss: 0.6101 - val_accuracy: 0.4500 - val_loss: 1.5438\n",
      "Epoch 68/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.7669 - loss: 0.6789 - val_accuracy: 0.4667 - val_loss: 1.4763\n",
      "Epoch 69/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.7607 - loss: 0.6575 - val_accuracy: 0.4833 - val_loss: 1.5154\n",
      "Epoch 70/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.8243 - loss: 0.5434 - val_accuracy: 0.5167 - val_loss: 1.4650\n",
      "Epoch 71/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 5s/step - accuracy: 0.7686 - loss: 0.6135 - val_accuracy: 0.5333 - val_loss: 1.4669\n",
      "Epoch 72/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.8113 - loss: 0.5741 - val_accuracy: 0.4667 - val_loss: 1.5377\n",
      "Epoch 73/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 4s/step - accuracy: 0.8282 - loss: 0.5869 - val_accuracy: 0.5000 - val_loss: 1.6173\n",
      "Epoch 74/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.8160 - loss: 0.5774 - val_accuracy: 0.4833 - val_loss: 1.6158\n",
      "Epoch 75/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.8064 - loss: 0.5832 - val_accuracy: 0.4833 - val_loss: 1.6400\n",
      "Epoch 76/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8052 - loss: 0.5778 - val_accuracy: 0.4167 - val_loss: 1.6560\n",
      "Epoch 77/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8114 - loss: 0.5593 - val_accuracy: 0.4500 - val_loss: 1.6802\n",
      "Epoch 78/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.7984 - loss: 0.5590 - val_accuracy: 0.4333 - val_loss: 1.6966\n",
      "Epoch 79/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.8232 - loss: 0.5842 - val_accuracy: 0.4500 - val_loss: 1.7534\n",
      "Epoch 80/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 4s/step - accuracy: 0.8163 - loss: 0.5597 - val_accuracy: 0.3833 - val_loss: 1.8876\n",
      "Epoch 81/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8060 - loss: 0.5757 - val_accuracy: 0.4000 - val_loss: 1.8174\n",
      "Epoch 82/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.8235 - loss: 0.4863 - val_accuracy: 0.4667 - val_loss: 1.6570\n",
      "Epoch 83/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.8041 - loss: 0.6154 - val_accuracy: 0.5000 - val_loss: 1.6983\n",
      "Epoch 84/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.8027 - loss: 0.5663 - val_accuracy: 0.4333 - val_loss: 1.7648\n",
      "Epoch 85/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8291 - loss: 0.5215 - val_accuracy: 0.4500 - val_loss: 1.7593\n",
      "Epoch 86/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8242 - loss: 0.5723 - val_accuracy: 0.4167 - val_loss: 2.5503\n",
      "Epoch 87/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.7962 - loss: 0.5704 - val_accuracy: 0.4167 - val_loss: 1.7162\n",
      "Epoch 88/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8537 - loss: 0.4791 - val_accuracy: 0.4167 - val_loss: 1.7254\n",
      "Epoch 89/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8542 - loss: 0.4850 - val_accuracy: 0.3833 - val_loss: 1.7145\n",
      "Epoch 90/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 47s/step - accuracy: 0.7859 - loss: 0.5719 - val_accuracy: 0.4333 - val_loss: 1.6771\n",
      "Epoch 91/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - accuracy: 0.8515 - loss: 0.4564 - val_accuracy: 0.4500 - val_loss: 1.6758\n",
      "Epoch 92/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.8325 - loss: 0.4909 - val_accuracy: 0.4667 - val_loss: 1.6877\n",
      "Epoch 93/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8038 - loss: 0.5459 - val_accuracy: 0.4500 - val_loss: 1.7445\n",
      "Epoch 94/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 0.8378 - loss: 0.5070 - val_accuracy: 0.4500 - val_loss: 1.8298\n",
      "Epoch 95/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 4s/step - accuracy: 0.8581 - loss: 0.4626 - val_accuracy: 0.5000 - val_loss: 1.7955\n",
      "Epoch 96/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.8624 - loss: 0.4588 - val_accuracy: 0.5000 - val_loss: 1.8834\n",
      "Epoch 97/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.8607 - loss: 0.4345 - val_accuracy: 0.4833 - val_loss: 1.8574\n",
      "Epoch 98/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8388 - loss: 0.4607 - val_accuracy: 0.5000 - val_loss: 1.8396\n",
      "Epoch 99/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.8379 - loss: 0.4433 - val_accuracy: 0.4667 - val_loss: 1.7674\n",
      "Epoch 100/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8470 - loss: 0.4943 - val_accuracy: 0.4667 - val_loss: 1.7333\n",
      "Epoch 101/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.8433 - loss: 0.4999 - val_accuracy: 0.4500 - val_loss: 1.6877\n",
      "Epoch 102/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8465 - loss: 0.4561 - val_accuracy: 0.4167 - val_loss: 1.7453\n",
      "Epoch 103/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8371 - loss: 0.5014 - val_accuracy: 0.4500 - val_loss: 1.7657\n",
      "Epoch 104/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8550 - loss: 0.4544 - val_accuracy: 0.4000 - val_loss: 1.8620\n",
      "Epoch 105/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - accuracy: 0.8295 - loss: 0.5039 - val_accuracy: 0.4667 - val_loss: 1.7100\n",
      "Epoch 106/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8384 - loss: 0.4285 - val_accuracy: 0.4667 - val_loss: 1.6604\n",
      "Epoch 107/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.8380 - loss: 0.4977 - val_accuracy: 0.5000 - val_loss: 1.6287\n",
      "Epoch 108/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.8325 - loss: 0.4319 - val_accuracy: 0.4667 - val_loss: 1.6759\n",
      "Epoch 109/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8043 - loss: 0.5467 - val_accuracy: 0.4667 - val_loss: 1.7068\n",
      "Epoch 110/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.8967 - loss: 0.3819 - val_accuracy: 0.4500 - val_loss: 1.7448\n",
      "Epoch 111/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8490 - loss: 0.4327 - val_accuracy: 0.4833 - val_loss: 1.7619\n",
      "Epoch 112/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8495 - loss: 0.4334 - val_accuracy: 0.4833 - val_loss: 1.7145\n",
      "Epoch 113/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 4s/step - accuracy: 0.8134 - loss: 0.5056 - val_accuracy: 0.5000 - val_loss: 1.7268\n",
      "Epoch 114/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8415 - loss: 0.4766 - val_accuracy: 0.4833 - val_loss: 1.7570\n",
      "Epoch 115/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.8673 - loss: 0.4441 - val_accuracy: 0.4500 - val_loss: 1.7466\n",
      "Epoch 116/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.8794 - loss: 0.3994 - val_accuracy: 0.4833 - val_loss: 1.7343\n",
      "Epoch 117/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8472 - loss: 0.4540 - val_accuracy: 0.4167 - val_loss: 1.9476\n",
      "Epoch 118/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8456 - loss: 0.4772 - val_accuracy: 0.4333 - val_loss: 1.8788\n",
      "Epoch 119/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 5s/step - accuracy: 0.8357 - loss: 0.4983 - val_accuracy: 0.4667 - val_loss: 1.7737\n",
      "Epoch 120/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 6s/step - accuracy: 0.8679 - loss: 0.4110 - val_accuracy: 0.4667 - val_loss: 1.7533\n",
      "Epoch 121/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 6s/step - accuracy: 0.8661 - loss: 0.4182 - val_accuracy: 0.5167 - val_loss: 1.6719\n",
      "Epoch 122/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 6s/step - accuracy: 0.8441 - loss: 0.4336 - val_accuracy: 0.5167 - val_loss: 1.6251\n",
      "Epoch 123/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8444 - loss: 0.4437 - val_accuracy: 0.4667 - val_loss: 1.7145\n",
      "Epoch 124/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.8319 - loss: 0.5113 - val_accuracy: 0.4500 - val_loss: 1.8202\n",
      "Epoch 125/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 5s/step - accuracy: 0.8658 - loss: 0.4047 - val_accuracy: 0.4333 - val_loss: 1.9210\n",
      "Epoch 126/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 5s/step - accuracy: 0.8762 - loss: 0.3997 - val_accuracy: 0.4167 - val_loss: 1.8536\n",
      "Epoch 127/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.8312 - loss: 0.4855 - val_accuracy: 0.4167 - val_loss: 2.0736\n",
      "Epoch 128/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 5s/step - accuracy: 0.8704 - loss: 0.3995 - val_accuracy: 0.4500 - val_loss: 2.0300\n",
      "Epoch 129/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 5s/step - accuracy: 0.8355 - loss: 0.4705 - val_accuracy: 0.3833 - val_loss: 2.1227\n",
      "Epoch 130/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 0.8763 - loss: 0.3646 - val_accuracy: 0.4167 - val_loss: 1.9847\n",
      "Epoch 131/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 5s/step - accuracy: 0.8858 - loss: 0.3588 - val_accuracy: 0.4833 - val_loss: 1.9772\n",
      "Epoch 132/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 5s/step - accuracy: 0.8519 - loss: 0.3788 - val_accuracy: 0.4667 - val_loss: 1.8331\n",
      "Epoch 133/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 8s/step - accuracy: 0.8530 - loss: 0.4201 - val_accuracy: 0.4167 - val_loss: 1.8248\n",
      "Epoch 134/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 6s/step - accuracy: 0.8585 - loss: 0.4180 - val_accuracy: 0.4167 - val_loss: 1.8384\n",
      "Epoch 135/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 7s/step - accuracy: 0.8716 - loss: 0.4027 - val_accuracy: 0.5000 - val_loss: 1.7677\n",
      "Epoch 136/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 5s/step - accuracy: 0.8670 - loss: 0.3894 - val_accuracy: 0.5500 - val_loss: 1.6949\n",
      "Epoch 137/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 6s/step - accuracy: 0.8831 - loss: 0.3827 - val_accuracy: 0.5167 - val_loss: 1.7410\n",
      "Epoch 138/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 5s/step - accuracy: 0.8254 - loss: 0.4645 - val_accuracy: 0.4667 - val_loss: 1.8738\n",
      "Epoch 139/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 5s/step - accuracy: 0.8337 - loss: 0.4128 - val_accuracy: 0.4833 - val_loss: 1.9308\n",
      "Epoch 140/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8589 - loss: 0.4413 - val_accuracy: 0.4500 - val_loss: 2.0560\n",
      "Epoch 141/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8644 - loss: 0.3940 - val_accuracy: 0.4500 - val_loss: 1.9737\n",
      "Epoch 142/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.8566 - loss: 0.4850 - val_accuracy: 0.4500 - val_loss: 1.8981\n",
      "Epoch 143/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8703 - loss: 0.3930 - val_accuracy: 0.4500 - val_loss: 1.8434\n",
      "Epoch 144/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.8271 - loss: 0.4832 - val_accuracy: 0.4500 - val_loss: 1.8009\n",
      "Epoch 145/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8767 - loss: 0.3786 - val_accuracy: 0.4667 - val_loss: 1.8444\n",
      "Epoch 146/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.8503 - loss: 0.4510 - val_accuracy: 0.4667 - val_loss: 1.8460\n",
      "Epoch 147/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 4s/step - accuracy: 0.8930 - loss: 0.3318 - val_accuracy: 0.4667 - val_loss: 1.7959\n",
      "Epoch 148/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 5s/step - accuracy: 0.8833 - loss: 0.3492 - val_accuracy: 0.4667 - val_loss: 1.8480\n",
      "Epoch 149/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8658 - loss: 0.4038 - val_accuracy: 0.4667 - val_loss: 1.8579\n",
      "Epoch 150/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8916 - loss: 0.3179 - val_accuracy: 0.5000 - val_loss: 1.8899\n",
      "Epoch 151/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8679 - loss: 0.4110 - val_accuracy: 0.4167 - val_loss: 2.0514\n",
      "Epoch 152/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5s/step - accuracy: 0.8687 - loss: 0.4145 - val_accuracy: 0.4000 - val_loss: 2.0799\n",
      "Epoch 153/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8525 - loss: 0.3967 - val_accuracy: 0.4167 - val_loss: 1.9929\n",
      "Epoch 154/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - accuracy: 0.9143 - loss: 0.2648 - val_accuracy: 0.4500 - val_loss: 1.9648\n",
      "Epoch 155/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8447 - loss: 0.4503 - val_accuracy: 0.4833 - val_loss: 1.8479\n",
      "Epoch 156/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 5s/step - accuracy: 0.8822 - loss: 0.3867 - val_accuracy: 0.4500 - val_loss: 1.8558\n",
      "Epoch 157/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.8655 - loss: 0.4260 - val_accuracy: 0.4667 - val_loss: 1.9282\n",
      "Epoch 158/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.8742 - loss: 0.3502 - val_accuracy: 0.4333 - val_loss: 1.9968\n",
      "Epoch 159/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8593 - loss: 0.4207 - val_accuracy: 0.4333 - val_loss: 2.0386\n",
      "Epoch 160/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.8695 - loss: 0.3589 - val_accuracy: 0.4333 - val_loss: 1.8808\n",
      "Epoch 161/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.8323 - loss: 0.4415 - val_accuracy: 0.4833 - val_loss: 1.7036\n",
      "Epoch 162/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8792 - loss: 0.3841 - val_accuracy: 0.5000 - val_loss: 1.7295\n",
      "Epoch 163/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8890 - loss: 0.3627 - val_accuracy: 0.4833 - val_loss: 1.9001\n",
      "Epoch 164/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5s/step - accuracy: 0.9056 - loss: 0.3298 - val_accuracy: 0.4833 - val_loss: 1.8502\n",
      "Epoch 165/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8927 - loss: 0.3345 - val_accuracy: 0.5167 - val_loss: 1.8339\n",
      "Epoch 166/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8789 - loss: 0.3584 - val_accuracy: 0.4667 - val_loss: 1.9264\n",
      "Epoch 167/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5s/step - accuracy: 0.8573 - loss: 0.4275 - val_accuracy: 0.4833 - val_loss: 1.9195\n",
      "Epoch 168/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.8912 - loss: 0.3501 - val_accuracy: 0.5000 - val_loss: 1.9056\n",
      "Epoch 169/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 0.8815 - loss: 0.3210 - val_accuracy: 0.4833 - val_loss: 1.8862\n",
      "Epoch 170/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.8961 - loss: 0.3505 - val_accuracy: 0.5167 - val_loss: 2.5689\n",
      "Epoch 171/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 5s/step - accuracy: 0.8852 - loss: 0.3673 - val_accuracy: 0.4667 - val_loss: 1.9768\n",
      "Epoch 172/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8960 - loss: 0.3059 - val_accuracy: 0.4667 - val_loss: 1.9847\n",
      "Epoch 173/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8912 - loss: 0.3304 - val_accuracy: 0.5167 - val_loss: 2.0912\n",
      "Epoch 174/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 5s/step - accuracy: 0.8818 - loss: 0.3828 - val_accuracy: 0.5000 - val_loss: 2.1146\n",
      "Epoch 175/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.8833 - loss: 0.3502 - val_accuracy: 0.4833 - val_loss: 2.0923\n",
      "Epoch 176/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8882 - loss: 0.3705 - val_accuracy: 0.5167 - val_loss: 1.9852\n",
      "Epoch 177/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8950 - loss: 0.3301 - val_accuracy: 0.4833 - val_loss: 1.9450\n",
      "Epoch 178/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4s/step - accuracy: 0.8495 - loss: 0.3972 - val_accuracy: 0.4833 - val_loss: 2.0522\n",
      "Epoch 179/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 4s/step - accuracy: 0.8802 - loss: 0.3364 - val_accuracy: 0.4667 - val_loss: 2.0171\n",
      "Epoch 180/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8739 - loss: 0.4031 - val_accuracy: 0.4333 - val_loss: 1.9723\n",
      "Epoch 181/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 5s/step - accuracy: 0.8982 - loss: 0.3322 - val_accuracy: 0.4667 - val_loss: 1.9685\n",
      "Epoch 182/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8724 - loss: 0.3856 - val_accuracy: 0.4833 - val_loss: 1.9320\n",
      "Epoch 183/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8841 - loss: 0.3684 - val_accuracy: 0.4500 - val_loss: 1.9396\n",
      "Epoch 184/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 0.8373 - loss: 0.4106 - val_accuracy: 0.4333 - val_loss: 2.0422\n",
      "Epoch 185/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8756 - loss: 0.3395 - val_accuracy: 0.4333 - val_loss: 2.1319\n",
      "Epoch 186/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.8711 - loss: 0.3543 - val_accuracy: 0.4333 - val_loss: 2.2210\n",
      "Epoch 187/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8913 - loss: 0.2957 - val_accuracy: 0.4500 - val_loss: 2.2316\n",
      "Epoch 188/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.8838 - loss: 0.3532 - val_accuracy: 0.4500 - val_loss: 2.2515\n",
      "Epoch 189/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.8686 - loss: 0.4147 - val_accuracy: 0.4667 - val_loss: 2.2082\n",
      "Epoch 190/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8822 - loss: 0.3573 - val_accuracy: 0.4500 - val_loss: 2.2101\n",
      "Epoch 191/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.8827 - loss: 0.3387 - val_accuracy: 0.4667 - val_loss: 2.2417\n",
      "Epoch 192/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.8640 - loss: 0.3861 - val_accuracy: 0.5000 - val_loss: 2.1380\n",
      "Epoch 193/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8861 - loss: 0.3772 - val_accuracy: 0.5333 - val_loss: 2.0055\n",
      "Epoch 194/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9129 - loss: 0.3020 - val_accuracy: 0.5500 - val_loss: 1.8950\n",
      "Epoch 195/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8910 - loss: 0.2950 - val_accuracy: 0.5333 - val_loss: 1.8633\n",
      "Epoch 196/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - accuracy: 0.8768 - loss: 0.3604 - val_accuracy: 0.5500 - val_loss: 1.8333\n",
      "Epoch 197/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8827 - loss: 0.3466 - val_accuracy: 0.5333 - val_loss: 1.9182\n",
      "Epoch 198/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8869 - loss: 0.3464 - val_accuracy: 0.5500 - val_loss: 1.9298\n",
      "Epoch 199/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 0.9217 - loss: 0.2960 - val_accuracy: 0.5333 - val_loss: 1.8391\n",
      "Epoch 200/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.8858 - loss: 0.3628 - val_accuracy: 0.5500 - val_loss: 1.8571\n",
      "Epoch 201/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.8969 - loss: 0.3097 - val_accuracy: 0.5000 - val_loss: 1.9147\n",
      "Epoch 202/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.8657 - loss: 0.3765 - val_accuracy: 0.5000 - val_loss: 2.0353\n",
      "Epoch 203/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.8929 - loss: 0.3030 - val_accuracy: 0.5167 - val_loss: 1.9716\n",
      "Epoch 204/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.8833 - loss: 0.3373 - val_accuracy: 0.5667 - val_loss: 1.8952\n",
      "Epoch 205/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.8806 - loss: 0.3530 - val_accuracy: 0.5000 - val_loss: 1.9143\n",
      "Epoch 206/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 4s/step - accuracy: 0.8942 - loss: 0.3497 - val_accuracy: 0.5333 - val_loss: 1.9700\n",
      "Epoch 207/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.8798 - loss: 0.3639 - val_accuracy: 0.5000 - val_loss: 1.9463\n",
      "Epoch 208/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 0.8780 - loss: 0.3658 - val_accuracy: 0.4833 - val_loss: 1.8380\n",
      "Epoch 209/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - accuracy: 0.8822 - loss: 0.3327 - val_accuracy: 0.5167 - val_loss: 1.9078\n",
      "Epoch 210/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - accuracy: 0.8875 - loss: 0.3668 - val_accuracy: 0.5167 - val_loss: 1.9343\n",
      "Epoch 211/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.8478 - loss: 0.4240 - val_accuracy: 0.5333 - val_loss: 1.9269\n",
      "Epoch 212/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.9002 - loss: 0.3324 - val_accuracy: 0.5000 - val_loss: 1.8620\n",
      "Epoch 213/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8569 - loss: 0.4417 - val_accuracy: 0.5000 - val_loss: 1.8498\n",
      "Epoch 214/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8994 - loss: 0.3089 - val_accuracy: 0.5000 - val_loss: 1.8187\n",
      "Epoch 215/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 0.8641 - loss: 0.3547 - val_accuracy: 0.4833 - val_loss: 1.8475\n",
      "Epoch 216/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8603 - loss: 0.3741 - val_accuracy: 0.4667 - val_loss: 1.9078\n",
      "Epoch 217/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5s/step - accuracy: 0.8963 - loss: 0.3042 - val_accuracy: 0.5000 - val_loss: 1.8774\n",
      "Epoch 218/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.9066 - loss: 0.2849 - val_accuracy: 0.5500 - val_loss: 1.7989\n",
      "Epoch 219/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8870 - loss: 0.3586 - val_accuracy: 0.5333 - val_loss: 1.8432\n",
      "Epoch 220/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8993 - loss: 0.3161 - val_accuracy: 0.5167 - val_loss: 1.9262\n",
      "Epoch 221/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.8661 - loss: 0.3442 - val_accuracy: 0.5167 - val_loss: 1.9159\n",
      "Epoch 222/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.8735 - loss: 0.3172 - val_accuracy: 0.4833 - val_loss: 1.8140\n",
      "Epoch 223/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.9015 - loss: 0.3063 - val_accuracy: 0.5000 - val_loss: 1.7648\n",
      "Epoch 224/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.9138 - loss: 0.2521 - val_accuracy: 0.5000 - val_loss: 1.8989\n",
      "Epoch 225/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.8884 - loss: 0.3448 - val_accuracy: 0.5000 - val_loss: 1.9404\n",
      "Epoch 226/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.8899 - loss: 0.3537 - val_accuracy: 0.5167 - val_loss: 1.9672\n",
      "Epoch 227/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8886 - loss: 0.2849 - val_accuracy: 0.5333 - val_loss: 1.8991\n",
      "Epoch 228/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8846 - loss: 0.3487 - val_accuracy: 0.5333 - val_loss: 1.9084\n",
      "Epoch 229/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.8972 - loss: 0.3451 - val_accuracy: 0.5000 - val_loss: 1.9336\n",
      "Epoch 230/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 4s/step - accuracy: 0.8960 - loss: 0.3219 - val_accuracy: 0.4833 - val_loss: 1.9596\n",
      "Epoch 231/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.9130 - loss: 0.3118 - val_accuracy: 0.5000 - val_loss: 2.0237\n",
      "Epoch 232/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.9188 - loss: 0.2365 - val_accuracy: 0.5000 - val_loss: 2.0384\n",
      "Epoch 233/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9090 - loss: 0.2760 - val_accuracy: 0.4833 - val_loss: 2.0578\n",
      "Epoch 234/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8845 - loss: 0.3201 - val_accuracy: 0.4667 - val_loss: 2.1549\n",
      "Epoch 235/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9047 - loss: 0.2869 - val_accuracy: 0.4667 - val_loss: 2.1993\n",
      "Epoch 236/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9208 - loss: 0.2699 - val_accuracy: 0.4500 - val_loss: 2.2777\n",
      "Epoch 237/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8851 - loss: 0.3362 - val_accuracy: 0.4167 - val_loss: 2.2515\n",
      "Epoch 238/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.9152 - loss: 0.2680 - val_accuracy: 0.4500 - val_loss: 2.1911\n",
      "Epoch 239/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8862 - loss: 0.3199 - val_accuracy: 0.4167 - val_loss: 2.2801\n",
      "Epoch 240/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8793 - loss: 0.3228 - val_accuracy: 0.4167 - val_loss: 2.2136\n",
      "Epoch 241/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8904 - loss: 0.3321 - val_accuracy: 0.4667 - val_loss: 2.1439\n",
      "Epoch 242/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 5s/step - accuracy: 0.9055 - loss: 0.3067 - val_accuracy: 0.4667 - val_loss: 2.1192\n",
      "Epoch 243/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9287 - loss: 0.2703 - val_accuracy: 0.4667 - val_loss: 2.1538\n",
      "Epoch 244/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8740 - loss: 0.3195 - val_accuracy: 0.4833 - val_loss: 2.0914\n",
      "Epoch 245/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8767 - loss: 0.3073 - val_accuracy: 0.4667 - val_loss: 2.0148\n",
      "Epoch 246/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8993 - loss: 0.3072 - val_accuracy: 0.4833 - val_loss: 1.9956\n",
      "Epoch 247/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 5s/step - accuracy: 0.9085 - loss: 0.2640 - val_accuracy: 0.5333 - val_loss: 2.0592\n",
      "Epoch 248/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8591 - loss: 0.3528 - val_accuracy: 0.4667 - val_loss: 2.0692\n",
      "Epoch 249/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.8783 - loss: 0.3461 - val_accuracy: 0.5333 - val_loss: 2.0361\n",
      "Epoch 250/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8670 - loss: 0.3437 - val_accuracy: 0.5500 - val_loss: 1.9498\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=250, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "204 epochs\n",
    "340 min\n",
    "43.33%\n",
    "88.33-56.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2do mejor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.8944 - loss: 0.2958 - val_accuracy: 0.4833 - val_loss: 1.9573\n",
      "Epoch 2/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9024 - loss: 0.2903 - val_accuracy: 0.5000 - val_loss: 1.9266\n",
      "Epoch 3/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.9079 - loss: 0.2689 - val_accuracy: 0.4833 - val_loss: 1.9097\n",
      "Epoch 4/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8909 - loss: 0.3575 - val_accuracy: 0.4667 - val_loss: 2.0874\n",
      "Epoch 5/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8865 - loss: 0.2982 - val_accuracy: 0.4500 - val_loss: 2.1083\n",
      "Epoch 6/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9024 - loss: 0.2961 - val_accuracy: 0.5167 - val_loss: 2.0860\n",
      "Epoch 7/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8988 - loss: 0.2751 - val_accuracy: 0.5333 - val_loss: 2.1225\n",
      "Epoch 8/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.9192 - loss: 0.2944 - val_accuracy: 0.5333 - val_loss: 1.9758\n",
      "Epoch 9/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9028 - loss: 0.2920 - val_accuracy: 0.5333 - val_loss: 1.8794\n",
      "Epoch 10/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9037 - loss: 0.2846 - val_accuracy: 0.4833 - val_loss: 1.8660\n",
      "Epoch 11/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.8996 - loss: 0.2743 - val_accuracy: 0.4667 - val_loss: 1.8752\n",
      "Epoch 12/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9021 - loss: 0.2942 - val_accuracy: 0.5000 - val_loss: 1.8945\n",
      "Epoch 13/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.9149 - loss: 0.2640 - val_accuracy: 0.5000 - val_loss: 1.8909\n",
      "Epoch 14/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9034 - loss: 0.3134 - val_accuracy: 0.4833 - val_loss: 1.9388\n",
      "Epoch 15/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.9116 - loss: 0.2705 - val_accuracy: 0.4667 - val_loss: 2.0494\n",
      "Epoch 16/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8848 - loss: 0.2882 - val_accuracy: 0.4667 - val_loss: 2.0681\n",
      "Epoch 17/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.9048 - loss: 0.2871 - val_accuracy: 0.4667 - val_loss: 2.1409\n",
      "Epoch 18/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.9329 - loss: 0.2201 - val_accuracy: 0.4667 - val_loss: 2.2271\n",
      "Epoch 19/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9180 - loss: 0.2541 - val_accuracy: 0.4667 - val_loss: 2.1955\n",
      "Epoch 20/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.9061 - loss: 0.2471 - val_accuracy: 0.4667 - val_loss: 2.0892\n",
      "Epoch 21/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8914 - loss: 0.2670 - val_accuracy: 0.4500 - val_loss: 2.0931\n",
      "Epoch 22/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8943 - loss: 0.3019 - val_accuracy: 0.4333 - val_loss: 2.0373\n",
      "Epoch 23/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8945 - loss: 0.3051 - val_accuracy: 0.4500 - val_loss: 1.9343\n",
      "Epoch 24/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - accuracy: 0.8965 - loss: 0.3064 - val_accuracy: 0.4833 - val_loss: 1.8719\n",
      "Epoch 25/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9339 - loss: 0.2203 - val_accuracy: 0.4500 - val_loss: 1.9114\n",
      "Epoch 26/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.9141 - loss: 0.2460 - val_accuracy: 0.4667 - val_loss: 1.9624\n",
      "Epoch 27/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.9133 - loss: 0.3111 - val_accuracy: 0.3833 - val_loss: 2.1077\n",
      "Epoch 28/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9129 - loss: 0.2577 - val_accuracy: 0.4167 - val_loss: 2.1096\n",
      "Epoch 29/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.9230 - loss: 0.2163 - val_accuracy: 0.4333 - val_loss: 2.1102\n",
      "Epoch 30/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9135 - loss: 0.2320 - val_accuracy: 0.4500 - val_loss: 2.0183\n",
      "Epoch 31/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.9130 - loss: 0.2409 - val_accuracy: 0.5000 - val_loss: 1.8785\n",
      "Epoch 32/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.8925 - loss: 0.3250 - val_accuracy: 0.4833 - val_loss: 1.9099\n",
      "Epoch 33/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.9055 - loss: 0.2989 - val_accuracy: 0.4500 - val_loss: 2.0967\n",
      "Epoch 34/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.9290 - loss: 0.2554 - val_accuracy: 0.4500 - val_loss: 2.0938\n",
      "Epoch 35/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8886 - loss: 0.3197 - val_accuracy: 0.4333 - val_loss: 2.0252\n",
      "Epoch 36/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.9336 - loss: 0.2329 - val_accuracy: 0.4500 - val_loss: 2.0417\n",
      "Epoch 37/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.9108 - loss: 0.3257 - val_accuracy: 0.4333 - val_loss: 2.1571\n",
      "Epoch 38/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9039 - loss: 0.2589 - val_accuracy: 0.4500 - val_loss: 2.1663\n",
      "Epoch 39/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9040 - loss: 0.2619 - val_accuracy: 0.4667 - val_loss: 2.1451\n",
      "Epoch 40/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8664 - loss: 0.3489 - val_accuracy: 0.4833 - val_loss: 2.0945\n",
      "Epoch 41/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.9041 - loss: 0.2885 - val_accuracy: 0.4833 - val_loss: 2.0824\n",
      "Epoch 42/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.9027 - loss: 0.2695 - val_accuracy: 0.5000 - val_loss: 2.0943\n",
      "Epoch 43/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.9141 - loss: 0.2580 - val_accuracy: 0.5000 - val_loss: 2.1944\n",
      "Epoch 44/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8801 - loss: 0.3631 - val_accuracy: 0.5000 - val_loss: 2.2470\n",
      "Epoch 45/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8990 - loss: 0.2790 - val_accuracy: 0.5167 - val_loss: 2.1803\n",
      "Epoch 46/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8987 - loss: 0.2766 - val_accuracy: 0.5167 - val_loss: 2.1845\n",
      "Epoch 47/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.8996 - loss: 0.2992 - val_accuracy: 0.5000 - val_loss: 2.2614\n",
      "Epoch 48/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9034 - loss: 0.2751 - val_accuracy: 0.4500 - val_loss: 2.2784\n",
      "Epoch 49/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.9183 - loss: 0.2619 - val_accuracy: 0.4500 - val_loss: 2.2515\n",
      "Epoch 50/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.9149 - loss: 0.2517 - val_accuracy: 0.4833 - val_loss: 2.1697\n",
      "Epoch 51/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - accuracy: 0.9081 - loss: 0.2567 - val_accuracy: 0.4833 - val_loss: 2.1443\n",
      "Epoch 52/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8874 - loss: 0.3034 - val_accuracy: 0.4667 - val_loss: 2.1977\n",
      "Epoch 53/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9279 - loss: 0.2331 - val_accuracy: 0.4500 - val_loss: 2.2269\n",
      "Epoch 54/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8740 - loss: 0.3188 - val_accuracy: 0.4167 - val_loss: 2.4620\n",
      "Epoch 55/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.9041 - loss: 0.2845 - val_accuracy: 0.4167 - val_loss: 2.4626\n",
      "Epoch 56/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - accuracy: 0.9097 - loss: 0.2424 - val_accuracy: 0.4000 - val_loss: 2.5616\n",
      "Epoch 57/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.9119 - loss: 0.2390 - val_accuracy: 0.4167 - val_loss: 2.5352\n",
      "Epoch 58/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.9003 - loss: 0.2646 - val_accuracy: 0.4500 - val_loss: 2.4248\n",
      "Epoch 59/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.9249 - loss: 0.2166 - val_accuracy: 0.4167 - val_loss: 2.4477\n",
      "Epoch 60/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.8979 - loss: 0.2995 - val_accuracy: 0.4167 - val_loss: 2.2886\n",
      "Epoch 61/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.9224 - loss: 0.2475 - val_accuracy: 0.4500 - val_loss: 2.2262\n",
      "Epoch 62/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.8938 - loss: 0.3292 - val_accuracy: 0.4500 - val_loss: 2.2086\n",
      "Epoch 63/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.9082 - loss: 0.3214 - val_accuracy: 0.4667 - val_loss: 2.2737\n",
      "Epoch 64/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.9045 - loss: 0.2777 - val_accuracy: 0.5000 - val_loss: 2.2054\n",
      "Epoch 65/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 4s/step - accuracy: 0.9070 - loss: 0.2569 - val_accuracy: 0.4833 - val_loss: 2.1071\n",
      "Epoch 66/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.9254 - loss: 0.2665 - val_accuracy: 0.4667 - val_loss: 2.1423\n",
      "Epoch 67/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.9279 - loss: 0.2154 - val_accuracy: 0.4833 - val_loss: 2.2600\n",
      "Epoch 68/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 4s/step - accuracy: 0.9050 - loss: 0.2633 - val_accuracy: 0.5167 - val_loss: 2.4253\n",
      "Epoch 69/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.9151 - loss: 0.2286 - val_accuracy: 0.4500 - val_loss: 2.4716\n",
      "Epoch 70/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.9040 - loss: 0.3089 - val_accuracy: 0.4333 - val_loss: 2.3480\n",
      "Epoch 71/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.9125 - loss: 0.2873 - val_accuracy: 0.4833 - val_loss: 2.3565\n",
      "Epoch 72/250\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 0.8847 - loss: 0.3104 - val_accuracy: 0.4667 - val_loss: 2.4315\n",
      "Epoch 73/250\n",
      "\u001b[1m17/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m9:17\u001b[0m 279s/step - accuracy: 0.9102 - loss: 0.2838 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=250, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4556 - loss: 2.5675\n",
      "Precisión en el conjunto de prueba: 43.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Precisión en el conjunto de prueba: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
