{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 55, 55, 48)        17472     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 48)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 27, 27, 48)       192       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 27, 27, 48)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 27, 128)       153728    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 13, 13, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 13, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 192)       221376    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 192)      768       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 192)       331968    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 13, 192)      768       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 128)       221312    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 6, 6, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              9439232   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,604,682\n",
      "Trainable params: 14,603,306\n",
      "Non-trainable params: 1,376\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - 17s 827ms/step - loss: 2.8923 - accuracy: 0.1400 - val_loss: 2.3328 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 14s 714ms/step - loss: 2.3889 - accuracy: 0.2267 - val_loss: 2.3381 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 15s 819ms/step - loss: 2.2106 - accuracy: 0.2717 - val_loss: 2.3864 - val_accuracy: 0.0667\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 17s 920ms/step - loss: 1.8863 - accuracy: 0.3400 - val_loss: 2.4886 - val_accuracy: 0.1000\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 15s 816ms/step - loss: 1.7825 - accuracy: 0.3833 - val_loss: 2.7069 - val_accuracy: 0.0833\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 17s 889ms/step - loss: 1.6479 - accuracy: 0.4333 - val_loss: 2.9206 - val_accuracy: 0.1000\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 16s 834ms/step - loss: 1.5007 - accuracy: 0.4900 - val_loss: 2.8016 - val_accuracy: 0.1000\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 17s 878ms/step - loss: 1.4721 - accuracy: 0.4917 - val_loss: 3.3028 - val_accuracy: 0.1167\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 16s 832ms/step - loss: 1.2862 - accuracy: 0.5550 - val_loss: 3.2631 - val_accuracy: 0.1000\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 18s 922ms/step - loss: 1.1920 - accuracy: 0.5900 - val_loss: 3.3054 - val_accuracy: 0.1000\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 15s 786ms/step - loss: 1.0378 - accuracy: 0.6400 - val_loss: 3.4436 - val_accuracy: 0.1000\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 18s 956ms/step - loss: 0.9633 - accuracy: 0.6717 - val_loss: 3.3060 - val_accuracy: 0.1000\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 15s 773ms/step - loss: 0.9222 - accuracy: 0.6600 - val_loss: 3.5335 - val_accuracy: 0.1167\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 15s 764ms/step - loss: 0.7376 - accuracy: 0.7250 - val_loss: 3.4264 - val_accuracy: 0.1000\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 16s 855ms/step - loss: 0.6288 - accuracy: 0.7800 - val_loss: 4.3140 - val_accuracy: 0.1333\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 16s 846ms/step - loss: 0.6162 - accuracy: 0.7933 - val_loss: 3.7130 - val_accuracy: 0.1500\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 15s 780ms/step - loss: 0.4871 - accuracy: 0.8217 - val_loss: 3.7623 - val_accuracy: 0.1000\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 15s 788ms/step - loss: 0.4794 - accuracy: 0.8367 - val_loss: 3.8043 - val_accuracy: 0.1500\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 14s 751ms/step - loss: 0.3961 - accuracy: 0.8683 - val_loss: 5.0568 - val_accuracy: 0.1167\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 14s 737ms/step - loss: 0.3742 - accuracy: 0.8783 - val_loss: 4.0237 - val_accuracy: 0.1500\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 15s 803ms/step - loss: 0.2910 - accuracy: 0.9050 - val_loss: 5.0757 - val_accuracy: 0.1667\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 0.2016 - accuracy: 0.9383 - val_loss: 4.8420 - val_accuracy: 0.1333\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 15s 784ms/step - loss: 0.2254 - accuracy: 0.9267 - val_loss: 4.9069 - val_accuracy: 0.1000\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 15s 796ms/step - loss: 0.2127 - accuracy: 0.9367 - val_loss: 4.0113 - val_accuracy: 0.2167\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 14s 751ms/step - loss: 0.1520 - accuracy: 0.9517 - val_loss: 4.5187 - val_accuracy: 0.1500\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 18s 942ms/step - loss: 0.1778 - accuracy: 0.9317 - val_loss: 5.8667 - val_accuracy: 0.1667\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 15s 779ms/step - loss: 0.1525 - accuracy: 0.9533 - val_loss: 3.3813 - val_accuracy: 0.3000\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 16s 816ms/step - loss: 0.1250 - accuracy: 0.9533 - val_loss: 3.6630 - val_accuracy: 0.2833\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 15s 821ms/step - loss: 0.0873 - accuracy: 0.9750 - val_loss: 4.0567 - val_accuracy: 0.3000\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 14s 751ms/step - loss: 0.1303 - accuracy: 0.9600 - val_loss: 4.4272 - val_accuracy: 0.3000\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 16s 836ms/step - loss: 0.1163 - accuracy: 0.9667 - val_loss: 4.7473 - val_accuracy: 0.2833\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 15s 773ms/step - loss: 0.1063 - accuracy: 0.9600 - val_loss: 3.5758 - val_accuracy: 0.4333\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 16s 830ms/step - loss: 0.0794 - accuracy: 0.9783 - val_loss: 4.3144 - val_accuracy: 0.4000\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 15s 799ms/step - loss: 0.0745 - accuracy: 0.9733 - val_loss: 4.0136 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 16s 816ms/step - loss: 0.0746 - accuracy: 0.9733 - val_loss: 3.5873 - val_accuracy: 0.4667\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 15s 777ms/step - loss: 0.0700 - accuracy: 0.9750 - val_loss: 4.0484 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 15s 812ms/step - loss: 0.0766 - accuracy: 0.9733 - val_loss: 4.1427 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 14s 750ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 4.7935 - val_accuracy: 0.3667\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 15s 805ms/step - loss: 0.1015 - accuracy: 0.9683 - val_loss: 3.6439 - val_accuracy: 0.4333\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 16s 835ms/step - loss: 0.0402 - accuracy: 0.9917 - val_loss: 3.7327 - val_accuracy: 0.4500\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 15s 806ms/step - loss: 0.0642 - accuracy: 0.9833 - val_loss: 4.1522 - val_accuracy: 0.3500\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 16s 825ms/step - loss: 0.0666 - accuracy: 0.9767 - val_loss: 3.5566 - val_accuracy: 0.4167\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 16s 831ms/step - loss: 0.0738 - accuracy: 0.9733 - val_loss: 3.8023 - val_accuracy: 0.4500\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 15s 788ms/step - loss: 0.0297 - accuracy: 0.9950 - val_loss: 3.8057 - val_accuracy: 0.5167\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 19s 961ms/step - loss: 0.0369 - accuracy: 0.9867 - val_loss: 3.7756 - val_accuracy: 0.4833\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 15s 791ms/step - loss: 0.0326 - accuracy: 0.9933 - val_loss: 3.8372 - val_accuracy: 0.4167\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 16s 848ms/step - loss: 0.0408 - accuracy: 0.9867 - val_loss: 3.9195 - val_accuracy: 0.3833\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 15s 778ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 3.6346 - val_accuracy: 0.5167\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 15s 772ms/step - loss: 0.0306 - accuracy: 0.9883 - val_loss: 3.7970 - val_accuracy: 0.5167\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 16s 809ms/step - loss: 0.0641 - accuracy: 0.9833 - val_loss: 4.0457 - val_accuracy: 0.3833\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 4.0457 - accuracy: 0.3833\n",
      "Precisión en el conjunto de prueba: 0.38333332538604736\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#region Read data\n",
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "folder_Train = os.path.join(base_dir, 'Train')\n",
    "folder_Test = os.path.join(base_dir, 'Test')\n",
    "\n",
    "img_size = (227, 227)\n",
    "# endregion\n",
    "\n",
    "#region Load Dataframe\n",
    "def load_images_from_df(df, folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        class_name = row['target']\n",
    "        img_path = os.path.join(folder, class_name, row['filename'])\n",
    "        try:\n",
    "            img = load_img(img_path, target_size=img_size)\n",
    "            img_array = img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(class_name)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"El archivo no fue encontrado: {img_path}\")\n",
    "    return np.array(images), labels\n",
    "#endregion\n",
    "\n",
    "#region Load imgs, codify labels and normalize imgs\n",
    "X_train, y_train = load_images_from_df(train_df, folder_Train)\n",
    "X_test, y_test = load_images_from_df(test_df, folder_Test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train_encoded)\n",
    "y_test_one_hot = to_categorical(y_test_encoded)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "#endregion\n",
    "\n",
    "#region Adjusted AlexNet\n",
    "def alex(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First layer\n",
    "    model.add(Conv2D(48, (11, 11), strides=4, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Second layer\n",
    "    model.add(Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Third, fourth, fifth (convolutional)\n",
    "    model.add(Conv2D(192, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(192, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Connected ones\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "#endregion\n",
    "\n",
    "#region Params, model and else\n",
    "input_shape = (img_size[0], img_size[1], 3)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "model = alex(input_shape, num_classes)\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_one_hot,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test_one_hot),\n",
    "    #callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Precisión en el conjunto de prueba: {test_acc}\")\n",
    "#endregion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capas Convolucionales: AlexNet tiene cinco capas convolucionales, que son responsables de extraer características clave de las imágenes. Las primeras capas capturan patrones básicos, como bordes y texturas, mientras que las capas más profundas capturan características más complejas. AlexNet utiliza filtros más grandes en sus primeras capas (11x11 y 5x5) y luego pasa a filtros más pequeños (3x3) en las capas posteriores. Cada capa convolucional está seguida de una función de activación ReLU para introducir no linealidad, lo que ayuda a la red a aprender representaciones más complejas.\n",
    "\n",
    "Capas de Pooling: AlexNet usa max-pooling después de las primeras, segundas y quintas capas convolucionales para reducir el tamaño de las imágenes. Esto disminuye la cantidad de parámetros, mejorando la eficiencia de la red y reduciendo la sensibilidad a pequeñas variaciones en las imágenes.\n",
    "\n",
    "Capas Completamente Conectadas: Al final de las capas convolucionales, AlexNet tiene dos capas completamente conectadas y una última capa de salida. Estas capas combinan las características extraídas en las capas anteriores para clasificar la imagen en una de las categorías predeterminadas. Las capas totalmente conectadas permiten que la red aprenda patrones más globales y contextuales de la imagen.\n",
    "\n",
    "Función de Activación: Al igual que en VGG19, AlexNet usa la función de activación ReLU en todas sus capas convolucionales y en las capas completamente conectadas. Esta función ayuda a que la red sea más eficiente, ya que permite aprender relaciones complejas de forma no lineal.\n",
    "\n",
    "Salida (Softmax): La última capa de AlexNet es una capa de softmax, que convierte las salidas en probabilidades para cada categoría. La red elige la categoría con la mayor probabilidad como predicción final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
